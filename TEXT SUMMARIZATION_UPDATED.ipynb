{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d000afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from language_tool_python import LanguageTool\n",
    "import spacy\n",
    "from heapq import nlargest\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c23274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import meteor_score\n",
    "from nltk.translate.meteor_score import single_meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d169ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load spaCy model for extractive text summarization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load T5 model and tokenizer for abstractive text summarization\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abf7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a0fd0",
   "metadata": {},
   "source": [
    "## Extractive Text Summarization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab62684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractive_summarize(text):\n",
    "    # Your extractive summarization logic here\n",
    "    # ...\n",
    "    # Get input text\n",
    "        #text = input_text.value\n",
    "\n",
    "        doc = nlp(text)\n",
    "\n",
    "        word_frequencies = {}\n",
    "        for word in doc:\n",
    "            if word.text.lower() not in custom_stopwords:\n",
    "                if word.text.lower() not in punctuation:\n",
    "                    if word.text not in word_frequencies.keys():\n",
    "                        word_frequencies[word.text] = 1\n",
    "                    else:\n",
    "                        word_frequencies[word.text] += 1\n",
    "\n",
    "        # SENTENCE TOKENIZATION\n",
    "        max_frequency = max(word_frequencies.values())\n",
    "        for word in word_frequencies.keys():\n",
    "            word_frequencies[word] = word_frequencies[word] / max_frequency\n",
    "\n",
    "        sentence_tokens = [sent for sent in doc.sents]\n",
    "\n",
    "        # WORD FREQUENCY TABLE\n",
    "        sentence_scores = {}\n",
    "        for sent in sentence_tokens:\n",
    "            for word in sent:\n",
    "                if word.text.lower() in word_frequencies.keys():\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "        from heapq import nlargest\n",
    "        select_length = int(len(sentence_tokens) * 0.3)\n",
    "        summary = nlargest(select_length, sentence_scores, key=sentence_scores.get)\n",
    "        final_summary = [word.text for word in summary]\n",
    "        generated_summary = ''.join(final_summary)\n",
    "        \n",
    "        return generated_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da1c1b",
   "metadata": {},
   "source": [
    "## Abstractive Text Summarization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab562fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractive_summarize(text):\n",
    "    # initialize the pretrained model\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "    device = torch.device('cpu')\n",
    "    preprocessed_text = text.strip().replace('\\n', '')\n",
    "    t5_input_text = 'summarize: ' + preprocessed_text\n",
    "\n",
    "    tokenized_text = tokenizer.encode(t5_input_text, return_tensors='pt', max_length=512).to(device)\n",
    "\n",
    "    summary_ids = model.generate(tokenized_text, min_length=30, max_length=300)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Post-process the summary for capitalization and grammar\n",
    "    tool = LanguageTool('en-US')\n",
    "    summary = tool.correct(summary)\n",
    "\n",
    "        # print(\"Generated Summary:\")\n",
    "        # print(summary)\n",
    "        \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b137c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856691e7676a4e48a452f45ad722ec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Extractive Summary:</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4c88efd75c4a5f9feb025556416d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"The start of Australia's chase was dented by India's new-ball bowling pair of Jasprit Bumrah and M…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb680b0047d48c39c2a8814353d10d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Abstractive Summary:</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4326c6863ee94e579e2906432fa7f18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"India's strong run at the world cup 2023 was put to a halt by Australia. The win was put to a halt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_summaries(btn):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Extractive Summarization\n",
    "    extractive_summary = extractive_summarize(text_area.value)\n",
    "\n",
    "    # Abstractive Summarization\n",
    "    abstractive_summary = abstractive_summarize(text_area.value)\n",
    "\n",
    "    # Display the results\n",
    "    display(widgets.HTML(\"<h3>Extractive Summary:</h3>\"))\n",
    "    display(widgets.HTML(extractive_summary))\n",
    "    display(widgets.HTML(\"<h3>Abstractive Summary:</h3>\"))\n",
    "    display(widgets.HTML(abstractive_summary))\n",
    "\n",
    "# Text area for input\n",
    "text_area = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter your text here...',\n",
    "    description='Input Text:',\n",
    "    layout=widgets.Layout(width='50%', height='200px')\n",
    ")\n",
    "\n",
    "# Button for triggering summarization\n",
    "summarize_button = widgets.Button(description=\"Summarize\", button_style='success')\n",
    "summarize_button.on_click(process_summaries)\n",
    "\n",
    "# Display widgets\n",
    "display(text_area)\n",
    "display(summarize_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eecfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
